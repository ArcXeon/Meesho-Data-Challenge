{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-11-04T16:02:45.466493Z",
     "iopub.status.busy": "2024-11-04T16:02:45.466102Z",
     "iopub.status.idle": "2024-11-04T16:02:45.901632Z",
     "shell.execute_reply": "2024-11-04T16:02:45.900589Z",
     "shell.execute_reply.started": "2024-11-04T16:02:45.466443Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-04T16:02:45.903803Z",
     "iopub.status.busy": "2024-11-04T16:02:45.903372Z",
     "iopub.status.idle": "2024-11-04T16:03:11.579817Z",
     "shell.execute_reply": "2024-11-04T16:03:11.578629Z",
     "shell.execute_reply.started": "2024-11-04T16:02:45.903768Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# !pip install --upgrade transformers accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-04T16:03:11.581942Z",
     "iopub.status.busy": "2024-11-04T16:03:11.581526Z",
     "iopub.status.idle": "2024-11-04T16:03:11.801488Z",
     "shell.execute_reply": "2024-11-04T16:03:11.800726Z",
     "shell.execute_reply.started": "2024-11-04T16:03:11.581897Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('/kaggle/input/visual-taxonomy/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-04T16:03:11.80395Z",
     "iopub.status.busy": "2024-11-04T16:03:11.803646Z",
     "iopub.status.idle": "2024-11-04T16:03:11.835396Z",
     "shell.execute_reply": "2024-11-04T16:03:11.834487Z",
     "shell.execute_reply.started": "2024-11-04T16:03:11.803916Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-04T16:03:11.837208Z",
     "iopub.status.busy": "2024-11-04T16:03:11.836602Z",
     "iopub.status.idle": "2024-11-04T16:03:11.858239Z",
     "shell.execute_reply": "2024-11-04T16:03:11.857291Z",
     "shell.execute_reply.started": "2024-11-04T16:03:11.837164Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_df['Category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-04T16:03:11.897212Z",
     "iopub.status.busy": "2024-11-04T16:03:11.8969Z",
     "iopub.status.idle": "2024-11-04T16:03:17.808922Z",
     "shell.execute_reply": "2024-11-04T16:03:17.808113Z",
     "shell.execute_reply.started": "2024-11-04T16:03:11.897178Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from transformers import AutoFeatureExtractor, AutoModelForImageClassification\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Load the training data\n",
    "train_df = pd.read_csv('/kaggle/input/visual-taxonomy/train.csv')\n",
    "\n",
    "# Filter for Sarees category\n",
    "train_df = train_df[train_df['Category'] == 'Men Tshirts'].reset_index(drop=True)\n",
    "\n",
    "# List of attribute columns\n",
    "attribute_cols = ['attr_1', 'attr_2', 'attr_3', 'attr_4', 'attr_5']\n",
    "\n",
    "# Image directory\n",
    "image_dir = '/kaggle/input/visual-taxonomy/train_images'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-04T16:03:17.810856Z",
     "iopub.status.busy": "2024-11-04T16:03:17.810233Z",
     "iopub.status.idle": "2024-11-04T16:03:17.820417Z",
     "shell.execute_reply": "2024-11-04T16:03:17.819577Z",
     "shell.execute_reply.started": "2024-11-04T16:03:17.810811Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class TopsAttributeDataset(Dataset):\n",
    "    def __init__(self, dataframe, image_dir, feature_extractor, attribute):\n",
    "        self.data = dataframe.reset_index(drop=True)\n",
    "        self.image_dir = image_dir\n",
    "        self.feature_extractor = feature_extractor\n",
    "        self.attribute = attribute\n",
    "\n",
    "        # Create label mapping\n",
    "        self.labels = sorted(self.data[attribute].unique())\n",
    "        self.label_to_idx = {label: idx for idx, label in enumerate(self.labels)}\n",
    "        self.idx_to_label = {idx: label for idx, label in enumerate(self.labels)}\n",
    "        self.num_classes = len(self.labels)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Load Image\n",
    "        img_id = self.data.loc[idx, 'id']\n",
    "        img_path = os.path.join(self.image_dir, f\"{str(img_id).zfill(6)}.jpg\")\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        # Preprocess image\n",
    "        inputs = self.feature_extractor(images=image, return_tensors=\"pt\")\n",
    "\n",
    "        # Load Label\n",
    "        label = self.data.loc[idx, self.attribute]\n",
    "        label_idx = self.label_to_idx[label]\n",
    "        label_idx = torch.tensor(label_idx, dtype=torch.long)\n",
    "\n",
    "        return inputs['pixel_values'].squeeze(0), label_idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-04T16:03:17.822393Z",
     "iopub.status.busy": "2024-11-04T16:03:17.821698Z",
     "iopub.status.idle": "2024-11-04T16:03:17.837318Z",
     "shell.execute_reply": "2024-11-04T16:03:17.836518Z",
     "shell.execute_reply.started": "2024-11-04T16:03:17.822361Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class TestTopsDataset(Dataset):\n",
    "    def __init__(self, dataframe, image_dir, feature_extractor):\n",
    "        self.data = dataframe.reset_index(drop=True)\n",
    "        self.image_dir = image_dir\n",
    "        self.feature_extractor = feature_extractor\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_id = self.data.loc[idx, 'id']\n",
    "        img_path = os.path.join(self.image_dir, f\"{str(img_id).zfill(6)}.jpg\")\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        # Preprocess image\n",
    "        inputs = self.feature_extractor(images=image, return_tensors=\"pt\")\n",
    "\n",
    "        return inputs['pixel_values'].squeeze(0), img_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-04T16:03:17.869543Z",
     "iopub.status.busy": "2024-11-04T16:03:17.868948Z",
     "iopub.status.idle": "2024-11-04T16:03:33.25568Z",
     "shell.execute_reply": "2024-11-04T16:03:33.254703Z",
     "shell.execute_reply.started": "2024-11-04T16:03:17.8695Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model_name = './pvt_v2_b2'  \n",
    "from transformers import AutoProcessor\n",
    "feature_extractor = AutoProcessor.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-04T16:03:33.257672Z",
     "iopub.status.busy": "2024-11-04T16:03:33.256934Z",
     "iopub.status.idle": "2024-11-04T16:03:33.289851Z",
     "shell.execute_reply": "2024-11-04T16:03:33.289046Z",
     "shell.execute_reply.started": "2024-11-04T16:03:33.257612Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(torch.cuda.device_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-04T16:03:33.291417Z",
     "iopub.status.busy": "2024-11-04T16:03:33.291128Z",
     "iopub.status.idle": "2024-11-04T16:03:33.299663Z",
     "shell.execute_reply": "2024-11-04T16:03:33.298687Z",
     "shell.execute_reply.started": "2024-11-04T16:03:33.291385Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Training loop for each attribute\n",
    "for attribute in attribute_cols:\n",
    "    print(f\"\\nTraining model for {attribute}\")\n",
    "\n",
    "    # Drop NaNs only for the current attribute\n",
    "    df_attr = train_df[train_df[attribute].notna()].reset_index(drop=True)\n",
    "\n",
    "    if df_attr.empty:\n",
    "        print(f\"No data available for {attribute}, skipping.\")\n",
    "        continue\n",
    "\n",
    "    # Create the dataset\n",
    "    dataset = TopsAttributeDataset(df_attr, image_dir, feature_extractor, attribute)\n",
    "\n",
    "    # Compute class weights\n",
    "    labels_list = [dataset.label_to_idx[label] for label in dataset.data[attribute]]\n",
    "    class_weights = compute_class_weight(\n",
    "        class_weight='balanced',\n",
    "        classes=np.arange(len(dataset.labels)),\n",
    "        y=labels_list\n",
    "    )\n",
    "    class_weights = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
    "\n",
    "    # Split into training and validation sets\n",
    "    train_indices, val_indices = train_test_split(\n",
    "        np.arange(len(dataset)),\n",
    "        test_size=0.2,\n",
    "        stratify=labels_list,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    train_dataset = torch.utils.data.Subset(dataset, train_indices)\n",
    "    val_dataset = torch.utils.data.Subset(dataset, val_indices)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=4, pin_memory=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "    # Instantiate the model with the correct number of labels\n",
    "    num_classes = len(dataset.labels)\n",
    "    model = AutoModelForImageClassification.from_pretrained(\n",
    "        model_name,\n",
    "        num_labels=num_classes,\n",
    "        ignore_mismatched_sizes=True\n",
    "    )\n",
    "\n",
    "    # Use all available GPUs\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        model = nn.DataParallel(model)\n",
    "\n",
    "    model = model.to(device)\n",
    "\n",
    "    # Unfreeze all layers for fine-tuning\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = True\n",
    "\n",
    "    # Define optimizer and loss function\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=1e-4)\n",
    "    criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "    # Training loop\n",
    "    num_epochs = 10\n",
    "    best_f1 = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "\n",
    "        with tqdm(train_loader, desc=f\"Epoch [{epoch+1}/{num_epochs}]\",\n",
    "                  leave=False, dynamic_ncols=True, mininterval=0.3) as pbar:\n",
    "            for pixel_values, labels_batch in pbar:\n",
    "                pixel_values = pixel_values.to(device)\n",
    "                labels_batch = labels_batch.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(pixel_values=pixel_values)\n",
    "                logits = outputs.logits\n",
    "                loss = criterion(logits, labels_batch)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                running_loss += loss.item()\n",
    "                pbar.set_postfix({'Loss': f'{loss.item():.4f}'})\n",
    "\n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Training Loss: {epoch_loss:.4f}\")\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for pixel_values, labels_batch in val_loader:\n",
    "                pixel_values = pixel_values.to(device)\n",
    "                labels_batch = labels_batch.to(device)\n",
    "                outputs = model(pixel_values=pixel_values)\n",
    "                logits = outputs.logits\n",
    "                loss = criterion(logits, labels_batch)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                _, predicted = torch.max(logits, 1)\n",
    "                all_preds.extend(predicted.cpu().numpy())\n",
    "                all_labels.extend(labels_batch.cpu().numpy())\n",
    "\n",
    "        val_loss /= len(val_loader)\n",
    "        f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "        print(f\"Validation Loss: {val_loss:.4f}, F1-Score: {f1:.4f}\")\n",
    "\n",
    "        unique_preds = np.unique(all_preds)\n",
    "        unique_labels = np.unique(all_labels)\n",
    "        print(f\"Unique Predictions: {unique_preds}\")\n",
    "        print(f\"Unique True Labels: {unique_labels}\")\n",
    "\n",
    "        pred_counts = Counter(all_preds)\n",
    "        label_counts = Counter(all_labels)\n",
    "        print(f\"Prediction Counts: {pred_counts}\")\n",
    "        print(f\"True Label Counts: {label_counts}\")\n",
    "\n",
    "        # Save the best model\n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            model_save_path = f'pvt_classifier_men_tshirts_{attribute}_best.pth'\n",
    "            # Save state_dict for multi-GPU compatibility\n",
    "            torch.save(model.module.state_dict(), model_save_path)\n",
    "            print(f\"Model saved for {attribute} with Validation F1-Score: {best_f1:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 9755748,
     "sourceId": 84705,
     "sourceType": "competition"
    },
    {
     "datasetId": 6009503,
     "sourceId": 9804507,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6009528,
     "sourceId": 9804538,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6009570,
     "sourceId": 9804606,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
