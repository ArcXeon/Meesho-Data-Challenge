{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoProcessor, AutoModelForImageClassification\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.base import clone\n",
    "from scipy.optimize import minimize\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('/kaggle/input/visual-taxonomy/train.csv')\n",
    "\n",
    "train_df = train_df[train_df['Category'] == 'Kurtis'].reset_index(drop=True)\n",
    "\n",
    "image_dir = '/kaggle/input/visual-taxonomy/train_images'\n",
    "\n",
    "attr_columns = ['attr_1', 'attr_2', 'attr_3', 'attr_4', 'attr_5','attr_6','attr_7','attr_8', 'attr_9', 'attr_10']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('/kaggle/input/visual-taxonomy/test.csv')\n",
    "\n",
    "test_df = test_df[test_df['Category'] == 'Kurtis'].reset_index(drop=True)\n",
    "\n",
    "test_image_dir = '/kaggle/input/visual-taxonomy/test_images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model_name = './pvt_v2_b2'\n",
    "feature_extractor = AutoProcessor.from_pretrained(model_name)\n",
    "model = AutoModelForImageClassification.from_pretrained(\n",
    "    model_name, output_hidden_states=True, ignore_mismatched_sizes=True)\n",
    "model.eval()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class FeatureExtractionDataset(Dataset):\n",
    "    def __init__(self, dataframe, image_dir, feature_extractor, image_size=(224, 224)):\n",
    "        self.data = dataframe.reset_index(drop=True)\n",
    "        self.image_dir = image_dir\n",
    "        self.feature_extractor = feature_extractor\n",
    "        self.image_size = image_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_id = self.data.loc[idx, 'id']\n",
    "        img_path = os.path.join(self.image_dir, f\"{str(img_id).zfill(6)}.jpg\")\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        # Resize the image to a consistent size\n",
    "        image = image.resize(self.image_size)\n",
    "        inputs = self.feature_extractor(images=image, return_tensors=\"pt\")\n",
    "        return inputs['pixel_values'].squeeze(0), img_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Initialize the submission DataFrame\n",
    "submission_df = pd.DataFrame({\n",
    "    'id': test_df['id'],\n",
    "    'Category': test_df['Category'],\n",
    "    'len': 9\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def harmonic_f1_score(y_true, y_pred):\n",
    "    f1_macro = f1_score(y_true, y_pred, average='macro')\n",
    "    f1_micro = f1_score(y_true, y_pred, average='micro')\n",
    "    harmonic_mean = 2 * (f1_macro * f1_micro) / (f1_macro + f1_micro + 1e-10)\n",
    "    return f1_macro, f1_micro, harmonic_mean\n",
    "\n",
    "def threshold_rounder(probs, thresholds):\n",
    "    num_samples, num_classes = probs.shape\n",
    "    preds = np.zeros(num_samples, dtype=int)\n",
    "    for i in range(num_samples):\n",
    "        adjusted_probs = probs[i] - thresholds\n",
    "        preds[i] = np.argmax(adjusted_probs)\n",
    "    return preds\n",
    "\n",
    "def evaluate_f1_thresholds(thresholds, y_true, probs):\n",
    "    y_pred = threshold_rounder(probs, thresholds)\n",
    "    _, _, harmonic_mean = harmonic_f1_score(y_true, y_pred)\n",
    "    return -harmonic_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def TrainML(model_class, X, y, test_data, n_splits=5, SEED=42):\n",
    "    SKF = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=SEED)\n",
    "    num_classes = len(np.unique(y))\n",
    "    oof_probs = np.zeros((len(y), num_classes))\n",
    "    test_probs = np.zeros((len(test_data), num_classes))\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(tqdm(SKF.split(X, y), desc=\"Training Folds\", total=n_splits)):\n",
    "        X_train, X_val = X[train_idx], X[val_idx]\n",
    "        y_train, y_val = y[train_idx], y[val_idx]\n",
    "\n",
    "        model = clone(model_class)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        y_val_probs = model.predict_proba(X_val)\n",
    "        oof_probs[val_idx] = y_val_probs\n",
    "\n",
    "        test_probs += model.predict_proba(test_data) / n_splits  # Averaging predictions\n",
    "\n",
    "    # Optimize thresholds\n",
    "    initial_thresholds = [0.5] * num_classes\n",
    "    bounds = [(0, 1)] * num_classes\n",
    "\n",
    "    optimized = minimize(\n",
    "        evaluate_f1_thresholds,\n",
    "        x0=initial_thresholds,\n",
    "        args=(y, oof_probs),\n",
    "        method='Nelder-Mead',\n",
    "        bounds=bounds\n",
    "    )\n",
    "\n",
    "    assert optimized.success, \"Optimization did not converge.\"\n",
    "\n",
    "    optimized_thresholds = optimized.x\n",
    "    oof_preds = threshold_rounder(oof_probs, optimized_thresholds)\n",
    "    test_preds = threshold_rounder(test_probs, optimized_thresholds)\n",
    "\n",
    "    # Calculate and print the scores\n",
    "    f1_macro, f1_micro, harmonic_mean = harmonic_f1_score(y, oof_preds)\n",
    "    print(f\"F1-Macro: {f1_macro:.4f}, F1-Micro: {f1_micro:.4f}, Harmonic Mean: {harmonic_mean:.4f}\")\n",
    "\n",
    "    return oof_preds, test_preds, optimized_thresholds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "for attr_idx, attr in enumerate(attr_columns, start=1):\n",
    "    print(f\"\\nProcessing {attr}...\")\n",
    "\n",
    "    # Drop rows with NaN\n",
    "    df = train_df.dropna(subset=[attr]).reset_index(drop=True)\n",
    "    if df.empty:\n",
    "        print(f\"No data available for {attr}, skipping.\")\n",
    "        submission_df[attr] = 'dummy_value'\n",
    "        continue\n",
    "\n",
    "    y_labels = df[attr].values\n",
    "\n",
    "    # Encode labels\n",
    "    label_encoder = LabelEncoder()\n",
    "    y = label_encoder.fit_transform(y_labels)\n",
    "    num_classes = len(np.unique(y))\n",
    "    print(num_classes)\n",
    "\n",
    "    # Handle cases where y has only one class\n",
    "    if num_classes < 2:\n",
    "        print(f\"Only one class present in {attr}, skipping training.\")\n",
    "        # Assign the single class to all test samples\n",
    "        test_preds_attr = np.full(len(test_df), y[0])\n",
    "    else:\n",
    "        # Load the model specific to the attribute\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        model_name = './pvt_v2_b2'\n",
    "        feature_extractor = AutoProcessor.from_pretrained(model_name)\n",
    "        model = AutoModelForImageClassification.from_pretrained(\n",
    "            model_name, num_labels=num_classes, output_hidden_states=True, ignore_mismatched_sizes=True)\n",
    "        model.to(device)\n",
    "        model.eval()\n",
    "\n",
    "        # Specify the model path for the current attribute\n",
    "        model_path = f\"./model weights/Kurtis/pvt_classifier_kurtis_attr_{attr_idx}_best.pth\"\n",
    "        if not os.path.exists(model_path):\n",
    "            print(f\"Model path {model_path} does not exist for {attr}, skipping.\")\n",
    "            submission_df[attr] = 'dummy_value'\n",
    "            continue\n",
    "\n",
    "        # Load the state dictionary\n",
    "        state_dict = torch.load(model_path, map_location=device)\n",
    "        model.load_state_dict(state_dict)\n",
    "        model.eval()\n",
    "\n",
    "        # Prepare the dataset for the current attribute\n",
    "        feature_dataset = FeatureExtractionDataset(df, image_dir, feature_extractor)\n",
    "        feature_loader = DataLoader(feature_dataset, batch_size=8, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "        # Extract features for training data with adaptive pooling\n",
    "        features_list = []\n",
    "        with torch.no_grad():\n",
    "            for pixel_values, img_ids in tqdm(feature_loader, desc=f\"Extracting Features for {attr}\"):\n",
    "                pixel_values = pixel_values.to(device)\n",
    "                outputs = model(pixel_values=pixel_values)\n",
    "                hidden_states = outputs.hidden_states[-1]  # Shape: (batch_size, channels, height, width)\n",
    "                # Apply adaptive pooling\n",
    "                pooled_features = F.adaptive_avg_pool2d(hidden_states, output_size=(1, 1))\n",
    "                pooled_features = pooled_features.view(pooled_features.size(0), -1).cpu().numpy()\n",
    "                features_list.append(pooled_features)\n",
    "        X_attr = np.concatenate(features_list, axis=0)\n",
    "\n",
    "        # Extract features for test data using the same model\n",
    "        test_feature_dataset = FeatureExtractionDataset(test_df, test_image_dir, feature_extractor)\n",
    "        test_feature_loader = DataLoader(test_feature_dataset, batch_size=8, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "        test_features_list = []\n",
    "        with torch.no_grad():\n",
    "            for pixel_values, img_ids in tqdm(test_feature_loader, desc=f\"Extracting Test Features for {attr}\"):\n",
    "                pixel_values = pixel_values.to(device)\n",
    "                outputs = model(pixel_values=pixel_values)\n",
    "                hidden_states = outputs.hidden_states[-1]\n",
    "                pooled_features = F.adaptive_avg_pool2d(hidden_states, output_size=(1, 1))\n",
    "                pooled_features = pooled_features.view(pooled_features.size(0), -1).cpu().numpy()\n",
    "                test_features_list.append(pooled_features)\n",
    "        test_features = np.concatenate(test_features_list, axis=0)\n",
    "\n",
    "        # Compute class weights\n",
    "        class_counts = Counter(y)\n",
    "        total_samples = len(y)\n",
    "        class_weights = {class_label: total_samples / count for class_label, count in class_counts.items()}\n",
    "        class_weights_list = [class_weights[i] for i in range(len(class_counts))]\n",
    "\n",
    "        # Define the classifier model\n",
    "        xgb_model = XGBClassifier(\n",
    "        n_estimators=200,              \n",
    "        learning_rate=0.05,                    \n",
    "        tree_method='hist',\n",
    "        device='cuda',               \n",
    "        random_state=42     \n",
    "        )\n",
    "\n",
    "        # Train the model\n",
    "        oof_preds, test_preds_attr, _ = TrainML(xgb_model, X_attr, y, test_features)\n",
    "\n",
    "    # Decode predictions\n",
    "    decoded_predictions = label_encoder.inverse_transform(test_preds_attr)\n",
    "\n",
    "    # Add predictions to the submission DataFrame\n",
    "    submission_df[attr] = decoded_predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Fill missing attribute columns with 'dummy_value'\n",
    "for attr in attr_columns:\n",
    "    if attr not in submission_df.columns:\n",
    "        submission_df[attr] = 'dummy_value'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Ensure the correct column order\n",
    "submission_df = submission_df[['id', 'Category', 'len'] + attr_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Save the submission file\n",
    "submission_df.to_csv('submission_kurtis.csv', index=False)\n",
    "print(\"Submission file created successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 9755748,
     "sourceId": 84705,
     "sourceType": "competition"
    },
    {
     "datasetId": 6012591,
     "sourceId": 9808717,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6020965,
     "sourceId": 9819820,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6022174,
     "sourceId": 9821378,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
